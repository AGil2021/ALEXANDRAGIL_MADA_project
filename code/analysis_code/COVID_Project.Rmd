---
title: "COVID-19 Project"
author: "Alexandra Gil"
date: "11/12/2021"
output: html_document
---

#load needed packages.
```{r}
library(dplyr) #for data processing
library(here) #to set paths
library(tidyverse)
library(lmtest) #assumptions validation
library(MASS) # for box-cox transformation
library(tree)
library(DT)

```

# Path to data

```{r}
data_location <- here::here("datacovid","raw_data","Provisional_COVID-19_Deaths_by_Sex_and_Age.csv")


rawdata <- read.csv(data_location)

col_types = cols(Year = col_factor(), 
Month = col_character(), 
Footnote = col_character())

```
# What is in my dataset?

```{r}
dplyr::glimpse(rawdata)
```
# Statistical Summary

```{r}
summary(rawdata)

table_year = table(rawdata$Year)
table_year %>%
  kbl() %>%
  kable_styling()
table_file = here("products","plots", "table_year.rds")
saveRDS(table_year, file = table_file)

table_states =table(rawdata$State)
table_states %>%
  kbl() %>%
  kable_styling()
table_file = here("products","plots", "table_states.rds")
saveRDS(table_states, file = table_file)

table_sex = table(rawdata$Sex)
table_sex %>%
  kbl() %>%
  kable_styling()
table_file = here("products","plots", "table_sex.rds")
saveRDS(table_sex, file = table_file)

table_age = table(rawdata$`Age Group`)
table_age %>%
  kbl() %>%
  kable_styling()
table_file = here("products","plots", "table_age.rds")
saveRDS(table_age, file = table_file)
```

# Correlations

Considering that the database has records of covid deaths, pneumonia deaths and influenza deaths, it is important to consider the correlation that may or may not exist between these variables.

```{r}
#correlations

cor(rawdata$'COVID.19.Deaths', rawdata$'Pneumonia.Deaths', use="complete.obs")

cor(rawdata$'COVID.19.Deaths', rawdata$'Influenza.Deaths', use="complete.obs")

cor(rawdata$'Pneumonia.Deaths', rawdata$'Influenza.Deaths', use="complete.obs")


```

| Correlations | Covid 19 deaths | Pneumonia deaths | Influenza deaths  |
|-------------------|-------------|---------------|--------------|
| Covid 19 deaths  |  1  |  0.9969512          | 0.8501622        |
| Pneumonia deaths  | 0.9969512  | 1         | 0.8667544        |
| Influenza deaths | 0.8501622 | 0.8667544  | 1       |

In this case, it was observed that the correlations are positive and greater than 0.5, therefore, it could be said that there is a direct relationship between the variables, the higher the number of deaths due to covid, the higher the number of deaths due to pneumonia and influenza.

# Filter Data

A filter of the database is made, where there is a focus mainly on people over 50 years of age, since according to studies it was the most vulnerable population in relation to covid, NA and zeros are filtered because in case the model is not significant and the assumption of normality is not met, it would have to resort to the box-cox transformation in order to check if the model improves, in addition to deaths above certain figures were taken into account to obtain a better visualization.


```{r}


newdata <- rawdata %>% filter(!Sex == "All Sexes")


newdata <- newdata %>% filter(!Age.Group == "All Ages" & !Age.Group == "Under 1 year" & !Age.Group== "0-17 years" &  !Age.Group == "1-4 years"  & !Age.Group == "1-4 years" & !Age.Group == "15-24 years" &!Age.Group == "5-14 years" & !Age.Group == "18-29 years" )


newdata <- newdata %>% filter(Group == "By Year")

newdata <- newdata %>% filter(!COVID.19.Deaths == "NA")

newdata <- newdata %>% filter(!COVID.19.Deaths == 0)

#newdata <- newdata %>% filter(!State == "United States")

newdata <- newdata %>% filter(COVID.19.Deaths >1000)

glimpse(newdata)
```

#Plots and Tables

```{r}
bp <- ggplot(newdata, aes( x = `COVID.19.Deaths`)) + geom_histogram()
bp
figure_file = here("products","plots","bp.png")
ggsave(filename = figure_file, plot=bp) 


histo <- ggplot(newdata, aes( x = `COVID.19.Deaths`)) + geom_histogram()+
        facet_grid(Sex ~ .)
histo
figure_file = here("products","plots","histo.png")
ggsave(filename = figure_file, plot=histo) 


bp1 <- ggplot(newdata, aes(x=`Pneumonia.Deaths`)) + geom_histogram()
bp1
figure_file = here("products","plots","bp1.png")
ggsave(filename = figure_file, plot=bp1) 

bp2 <- ggplot(newdata, aes(x=`Influenza.Deaths` ))+ geom_histogram()
bp2
figure_file = here("products","plots","bp2.png")
ggsave(filename = figure_file, plot=bp2) 


bp3 <- ggplot(newdata, aes(x=`Pneumonia.and.COVID.19.Deaths`))+ geom_histogram()
bp3
figure_file = here("products","plots","bp3.png")
ggsave(filename = figure_file, plot=bp3) 

```

#Model

```{r}
fit <- lm(`COVID.19.Deaths`~ `Age.Group`+State , data=newdata )

summary(fit)

layout(matrix(c(1,2,3,4),2,2))  

plot1<-plot(fit)

figure_file = here("products","plots","plot1.png")
ggsave(filename = figure_file, plot=plot1) 

```


It is observed then that in spite of having a relatively good coefficient of determination, there are problems related to the assumptions, and for this reason the box-cox transformation is used.


# Box-cox transformation


```{r}
bm=boxcox(as.numeric(newdata$COVID.19.Deaths) ~ newdata$Age.Group+ newdata$State )

lambda=bm$x[which(bm$y==max(bm$y))]

fit2 <- lm(COVID.19.Deaths^lambda~ Age.Group+State  , data=newdata)

summary(fit2)


```

After performing the box-cox transformation, the model is run again and an improvement in the coefficient of determination is observed and at the same time, graphically and analytically, it can be said that the assumptions of the model are being fulfilled (except for the autocorrelation assumption, but this could possibly be due to the nature of the data or the data collection). The assumptions were validated through tests such as shapiro wilks for normality, reset for linearity (although it is not very common to evaluate this assumption through an analytical test), Breusch-Pagan for the homogeneity of variance assumption and Durbin-Watson for the autocorrelation assumption.

# Assumption validation

```{r}
#lineality 
resettest(fit2)

# variance 
bptest(fit2)

# autocorrelation
dwtest(fit2,alternative = "two.sided")

# normality
shapiro.test(fit2$residuals)

```

# ANOVA

In this case, with a significance level of 0.05, significant differences are observed between the age groups and the state in which they are located.

```{r}
anova(fit2)

```


# machine learning model

In this case, a regression tree is used as a first approach to machine learning models, since the nature of this model deals with quantitative response variables.

```{r}

machinedata <- rawdata %>% filter(!Sex == "All Sexes")


machinedata <- machinedata %>% filter(!Age.Group == "All Ages"  )

machinedata <- machinedata %>% filter(Group == "By Year")



colnames(machinedata)[10] <- "coviddeats"
colnames(machinedata)[9] <- "age"

set.seed(123) # 
sampledata <- sample(1:nrow(machinedata), size = nrow(machinedata)/2) # sample
trainset <- machinedata[sampledata,] # train data
testset <- machinedata[-sampledata,] # test data


set.seed(123) # seed
treeregresion <- tree::tree(
        formula = as.numeric(coviddeats)~ as.factor(Sex)+as.factor(age), # Response variables and predictors variables
        data = trainset, # Data that will be used for the model creation 
        split = "deviance", # Deviation
        mincut = 20, # Minimum number of observations for division to occur
        minsize = 50 # Minimun number of observation for ramification
)

summary(treeregresion)

par(mar = c(1,1,1,1)) # plot margins
plot(x = treeregresion, type = "proportional") # Decision Tree Árbol (heterogeneity)
text(x = treeregresion, splits = TRUE, pretty = 0, cex = 0.8, col = "firebrick") # Tree Label


regression_tree <- tree( 
                    formula = as.numeric(coviddeats)~ as.factor(Sex)+as.factor(age),
                    data    = trainset,
                    split   = "deviance",
                    mincut  = 1,
                    minsize = 2,
                    mindev  = 0
                  )

set.seed(500) 
cv_arbol <- cv.tree(regression_tree, K = 5) 

cv_arbol


size <- rev(cv_arbol$size)[which.min(rev(cv_arbol$dev))] # Looking for the size
paste("Optimal size of the number of terminal nodes:", size)

final_tree <- prune.tree(
                  tree = regression_tree, # Tree size
                  best = size 
               )

predictions <- predict(regression_tree, newdata = testset)
test_rmse    <- sqrt(mean((predictions - testset$coviddeats)^2,na.rm=TRUE))
paste("Initial tree test error:", round(test_rmse,2))

predictions1 <- predict(final_tree, newdata = testset)
test_rmse1   <- sqrt(mean((predictions1 - testset$coviddeats)^2, na.rm=T))
paste("Final tree test error:", round(test_rmse1,2))
```

#Machine learning using newdata
```{r}

machinedata <- newdata
colnames(machinedata)[10] <- "coviddeats"
colnames(machinedata)[9] <- "age"

set.seed(123) # 
sampledata <- sample(1:nrow(machinedata), size = nrow(machinedata)/2) # sample
trainset <- machinedata[sampledata,] # train data
testset <- machinedata[-sampledata,] # test data


set.seed(123) # seed
treeregresion <- tree::tree(
        formula = as.numeric(coviddeats)~ as.factor(Sex)+as.factor(age), # Response variables and predictors variables
        data = trainset, # Data that will be used for the model creation 
        split = "deviance", # Deviation
        mincut = 20, # Minimum number of observations for division to occur
        minsize = 50 # Minimum number of observation for ramification
)

summary(treeregresion)

par(mar = c(1,1,1,1)) # plot margins
plot(x = treeregresion, type = "proportional") #  # Decision Tree Árbol (heterogeneity)
text(x = treeregresion, splits = TRUE, pretty = 0, cex = 0.8, col = "firebrick") #  Tree Label

regression_tree <- tree( 
                    formula = as.numeric(coviddeats)~ as.factor(Sex)+as.factor(age),
                    data    = trainset,
                    split   = "deviance",
                    mincut  = 1,
                    minsize = 2,
                    mindev  = 0
                  )

set.seed(500) 
cv_arbol <- cv.tree(regression_tree, K = 5) # cross crossing validation
cv_arbol


size <- rev(cv_arbol$size)[which.min(rev(cv_arbol$dev))] # Looking for the size
paste("Optimal size of the number of terminal nodes:", size)

final_tree <- prune.tree(
                  tree = regression_tree, #Tree size
                  best = size 
               )

predictions <- predict(regression_tree, newdata = testset)
test_rmse    <- sqrt(mean((predictions - testset$coviddeats)^2,na.rm=TRUE))
paste("Initial tree test error:", round(test_rmse,2))

predictions1 <- predict(final_tree, newdata = testset)
test_rmse1   <- sqrt(mean((predictions1 - testset$coviddeats)^2, na.rm=T))
paste("Final tree test error:", round(test_rmse1,2))
```

